apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: local-ai
  namespace: default
spec:
  interval: 1m
  chart:
    spec:
      chart: go-skynet
      version: "2.1.1"
      sourceRef:
        kind: HelmRepository
        name: go-skynet
        namespace: flux-system
  values:
    replicaCount: 1
    deployment:
      image: quay.io/go-skynet/local-ai:latest
      env:
        threads: 4
        context_size: 512
      modelsPath: "/models"
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 128Mi
    promptTemplates:
      ggml-gpt4all-j.tmpl: |
        The prompt below is a question to answer, a task to complete, or a conversation to respond to; decide which and write an appropriate response.
        ### Prompt:
        {{.Input}}
        ### Response:
    models:
      forceDownload: false
      list:
        - url: "https://gpt4all.io/models/ggml-gpt4all-j.bin"
          # basicAuth: base64EncodedCredentials
      persistence:
        pvc:
          enabled: false
          size: 6Gi
          accessModes:
            - ReadWriteOnce
          annotations: {}
          storageClass: longhorn
        hostPath:
          enabled: false
          path: "/models"
    nodeSelector: {}
    tolerations: []
    affinity: {}
